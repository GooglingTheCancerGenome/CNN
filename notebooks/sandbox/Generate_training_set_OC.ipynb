{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save a channel and label data for the NA12878 sample with the Mills2011_nanosv labels, for Chr[1,2,3]\n",
    "## This dataset is used as a reference test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "import gzip\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "def transposeDataset(X):\n",
    "    image = []\n",
    "    for i in range (0, len(X -1)):\n",
    "        tr = X[i].transpose()\n",
    "        image.append(tr)\n",
    "    return np.array(image)\n",
    "\n",
    "def write_prec_rec(y_binary, probs):\n",
    "    \n",
    "    df_conf = pd.DataFrame()\n",
    "\n",
    "    for i in np.linspace(1.0 / len(labels), 1, num=50, endpoint=False):\n",
    "\n",
    "        predicted = np.argwhere(probs > i)[:, 1]\n",
    "        y_index = np.argwhere(y_binary > i)[:, 1]\n",
    "\n",
    "        # Rows: true, columns: predicted\n",
    "        confusion_matrix = pd.crosstab(pd.Series(y_index), pd.Series(predicted))\n",
    "        confusion_matrix.index = [labels[i] for i in confusion_matrix.index]\n",
    "        confusion_matrix.columns = [labels[i] for i in confusion_matrix.columns]\n",
    "        confusion_matrix.reindex(columns=[l for l in labels], fill_value=0)\n",
    "\n",
    "        for l in labels:\n",
    "            if l in confusion_matrix.index:\n",
    "                \n",
    "                label_precision = np.around(confusion_matrix.loc[l, l] / sum(confusion_matrix.loc[:, l]) * 100)\n",
    "                label_recall = np.around(confusion_matrix.loc[l, l] / sum(confusion_matrix.loc[l, :]) * 100)\n",
    "                label_F1 = 2 * (label_precision * label_recall) / (label_precision + label_recall)\n",
    "\n",
    "                # print(f'Iter:{i} {l} -> Precision:{label_precision}%, Recall:{label_recall}%, F1:{label_F1}')\n",
    "\n",
    "                df_intres = pd.DataFrame(\n",
    "                    {'iteration': [i], 'label': [l],\n",
    "                     'precision': [label_precision], 'recall': [label_recall], 'F1': [label_F1]})\n",
    "                df_conf = df_conf.append(df_intres)\n",
    "\n",
    "    # print(df_conf)\n",
    "    df_conf.to_csv(path_or_buf=os.path.join(datapath_now,'model_PrecRec.csv'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_list = list(map(str, np.arange(1,23)))\n",
    "chr_list.extend(['X','Y'])\n",
    "\n",
    "date = '070119'\n",
    "label_type = 'bpi'\n",
    "base_dir = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData_'+date+'/'\n",
    "comparisons = os.listdir(base_dir)\n",
    "\n",
    "ids = []\n",
    "labels = []\n",
    "for sample_name in comparisons:\n",
    "    print('Loading %s labels...'%sample_name)\n",
    "    dico_file = base_dir+sample_name+'/MultiLabelData/labels.pickle.gz'\n",
    "    with gzip.GzipFile(dico_file, \"rb\") as f:\n",
    "        dico = np.load(f)\n",
    "    f.close()\n",
    "    for chrom_name in chr_list:\n",
    "        if chrom_name in dico[label_type].keys():\n",
    "            labels.extend(dico[label_type][chrom_name])\n",
    "            ids.extend(dico['id'][chrom_name])\n",
    "    \n",
    "print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "ids = np.array(ids)\n",
    "\n",
    "label_output_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData/all_labels.npy'\n",
    "np.save(label_output_file, labels)\n",
    "os.system('gzip '+label_output_file)\n",
    "\n",
    "id_output_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData/all_ids.npy'\n",
    "np.save(id_output_file, ids)\n",
    "os.system('gzip '+id_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_name = 'NA12878'\n",
    "# date = '231118'\n",
    "# label_type = 'bpi'\n",
    "\n",
    "# # Load label dictionary\n",
    "# dico_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData_'+date+'/'+sample_name+'/MultiLabelData/labels.pickle.gz'\n",
    "# with gzip.GzipFile(dico_file, \"rb\") as f:\n",
    "#     dico = np.load(f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(chr_list)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "ids = []\n",
    "\n",
    "for sample_name in comparisons:\n",
    "    \n",
    "    print('Loading sample: %s...'%sample_name)\n",
    "    datapath = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData_'+date+'/'+sample_name\n",
    "\n",
    "    partial_data = []\n",
    "    partial_labels = []\n",
    "    partial_id = []\n",
    "    \n",
    "    dico_file = datapath+'/MultiLabelData/labels.pickle.gz'\n",
    "    with gzip.GzipFile(dico_file, \"rb\") as f:\n",
    "        dico = np.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    print(dico[label_type].keys())\n",
    "    # print(chr_list)\n",
    "    \n",
    "    #for i in dico[label_type].keys():\n",
    "    for i in chr_list:\n",
    "        if i in dico[label_type].keys():\n",
    "            if not (sample_name == 'O16_B16' and i == '2'):\n",
    "\n",
    "                print('Loading data for Chr%s' % i)\n",
    "\n",
    "                partial_labels.extend(dico[label_type][i])\n",
    "                partial_id.extend([d['chromosome']+'_'+str(d['position']) for d in dico['id'][i]])\n",
    "\n",
    "                data_file = datapath+ '/ChannelData/'+ str(i) + '_channel_maker_real_germline.npy.gz'\n",
    "                with gzip.GzipFile(data_file, \"rb\") as f:\n",
    "                    data_mat = np.load(f)\n",
    "                    partial_data.extend(data_mat)\n",
    "                f.close()\n",
    "\n",
    "    partial_labels = np.array(partial_labels)\n",
    "    i_nosv = np.where(partial_labels=='noSV')[0]\n",
    "    \n",
    "    #print(i_nosv)\n",
    "    \n",
    "    i_nosv_idx = np.random.choice(a=i_nosv,\n",
    "                                  #size=int(np.round(i_nosv.shape[0]/100)),\n",
    "                                  size=100,\n",
    "                                  replace=False)\n",
    "    i_sv = np.where(partial_labels!='noSV')[0]\n",
    "    \n",
    "    partial_data = np.array(partial_data)\n",
    "    partial_data = np.append(partial_data[i_sv], partial_data[i_nosv_idx])\n",
    "    \n",
    "    partial_labels = np.array(partial_labels)\n",
    "    partial_data = np.append(partial_labels[i_sv], partial_labels[i_nosv_idx])\n",
    "    \n",
    "    partial_id = np.array(partial_id)\n",
    "    partial_id = np.append(partial_id[i_sv], partial_id[i_nosv_idx])\n",
    "    \n",
    "    data.extend(partial_data)\n",
    "    labels.extend(partial_labels)\n",
    "    ids.extend(partial_id)\n",
    "    \n",
    "print(Counter(labels))\n",
    "assert len(data) == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(data)\n",
    "training_labels = np.array(labels)\n",
    "training_id = np.array(ids)\n",
    "\n",
    "data_output_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData/data.npy'\n",
    "np.save(data_output_file, data)\n",
    "os.system('gzip '+data_output_file)\n",
    "\n",
    "label_output_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData/labels.npy'\n",
    "np.save(label_output_file, labels)\n",
    "os.system('gzip '+label_output_file)\n",
    "\n",
    "id_output_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData/ids.npy'\n",
    "np.save(id_output_file, ids)\n",
    "os.system('gzip '+id_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process training data from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "\n",
    "data_output_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData/data.npy.gz'\n",
    "\n",
    "with gzip.GzipFile(data_output_file, \"rb\") as f:\n",
    "    training_data = np.load(f)\n",
    "f.close()\n",
    "\n",
    "label_output_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData/labels.npy.gz'\n",
    "\n",
    "with gzip.GzipFile(label_output_file, \"rb\") as f:\n",
    "    training_labels = np.load(f)\n",
    "f.close()\n",
    "\n",
    "id_output_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData/ids.npy.gz'\n",
    "\n",
    "with gzip.GzipFile(id_output_file, \"rb\") as f:\n",
    "    training_id = np.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "training_id = np.array(training_id)\n",
    "\n",
    "for l in ['UK', 'INS_start']:\n",
    "    # Remove windows labelled as unknown ('UK')\n",
    "    keep = np.where(np.array(training_labels)!=l)\n",
    "    training_data = training_data[keep]\n",
    "    training_labels = training_labels[keep]\n",
    "    training_id = training_id[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_lab = Counter(training_labels)\n",
    "min_v = min([v for k, v in cnt_lab.items()])\n",
    "print(cnt_lab)\n",
    "print('Minimum number of labels = ' + str(min_v))\n",
    "\n",
    "data_balanced = []\n",
    "labels_balanced = []\n",
    "id_balanced = []\n",
    "\n",
    "for l in cnt_lab.keys():\n",
    "    #print(l)\n",
    "    iw = np.where(training_labels==l)\n",
    "    ii = iw[0][:min_v]\n",
    "    data_balanced.extend(training_data[ii])\n",
    "    labels_balanced.extend(training_labels[ii])\n",
    "    id_balanced.extend(training_id[ii])\n",
    "\n",
    "print(Counter(labels_balanced))\n",
    "\n",
    "X = np.array(data_balanced)\n",
    "y = np.array(labels_balanced)\n",
    "z = np.array(id_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_lab = Counter(training_labels)\n",
    "max_v = max([v for k, v in cnt_lab.items()])\n",
    "print(cnt_lab)\n",
    "print('Maximum number of labels = ' + str(max_v))\n",
    "\n",
    "data_balanced = []\n",
    "labels_balanced = []\n",
    "id_balanced = []\n",
    "\n",
    "for l in cnt_lab.keys():\n",
    "    #print(l)\n",
    "    iw = np.where(training_labels==l)\n",
    "    #ii = iw[0][:min_v]\n",
    "    ii = np.random.choice(a=iw[0], size=max_v, replace=True)\n",
    "    data_balanced.extend(training_data[ii])\n",
    "    labels_balanced.extend(training_labels[ii])\n",
    "    id_balanced.extend(training_id[ii])\n",
    "\n",
    "print(Counter(labels_balanced))\n",
    "\n",
    "X = np.array(data_balanced)\n",
    "y = np.array(labels_balanced)\n",
    "z = np.array(id_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(training_data)\n",
    "y = np.array(training_labels)\n",
    "z = np.array(training_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove windows with nan if present\n",
    "# print(np.where(np.isnan(X)))\n",
    "idx = np.unique(np.where(np.isnan(X))[0])\n",
    "print(idx)\n",
    "#print(X[np.where(np.isnan(X))])\n",
    "print(z[idx])\n",
    "idx = numpy.unique(np.where(np.isnan(X))[0])\n",
    "X = np.delete(X, idx, 0)\n",
    "y = np.delete(y, idx, 0)\n",
    "z = np.delete(z, idx, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC track seems fine at positions Chr4_1423148 and Chr4_1478645\n",
    "\n",
    "# import pyBigWig\n",
    "\n",
    "# bw_gc = pyBigWig.open(\"/hpc/cog_bioinf/ridder/users/lsantuari/Datasets/UCSC/hg19/hg19.gc5Base.bw\")\n",
    "\n",
    "# for loc in z[idx]:\n",
    "    \n",
    "#     chr_pos = loc.split('_')\n",
    "#     chrName = chr_pos[0]\n",
    "#     mid_pos = int(chr_pos[1])\n",
    "#     win = 200\n",
    "#     start_win = mid_pos-int(win/2)\n",
    "#     end_win = mid_pos+int(win/2)\n",
    "    \n",
    "#     gc_array = bw_gc.values('chr' + chrName, start_win, end_win)\n",
    "    \n",
    "#     print(mid_pos)\n",
    "#     print(gc_array)\n",
    "#     print(len(gc_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transposeDataset(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive mapclasses\n",
    "classes = sorted(list(set(y)))\n",
    "mapclasses = dict()\n",
    "for i, c in enumerate(classes):\n",
    "    mapclasses[c] = i\n",
    "# for ... in ...\n",
    "# mapclasses = {'DEL_start': 1, 'DEL_end': 0,  'noSV': 2}\n",
    "print(mapclasses)\n",
    "y_num = np.array([mapclasses[c] for c in y], dtype='int')\n",
    "y_binary = to_categorical(y_num)\n",
    "print(y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y_binary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save channels and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import errno\n",
    "\n",
    "datapath = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date\n",
    "datapath_training=os.path.join(datapath,'TrainingData/')\n",
    "\n",
    "try:\n",
    "    os.mkdir(datapath_training)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "data_output_file = datapath_training + 'OC' + '_' + label_type + '_upsampled.npz'\n",
    "np.savez(data_output_file, X=X, y=y, y_binary=y_binary, ids=z)\n",
    "os.system('gzip -f '+data_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_file = datapath_training + 'OC' + '_' + label_type + '.npz.gz'\n",
    "with gzip.GzipFile(data_output_file, \"rb\") as f:\n",
    "    npzfiles = np.load(f)\n",
    "    X_loaded = npzfiles['X']\n",
    "    y_loaded = npzfiles['y']\n",
    "    y_binary_loaded = npzfiles['y_binary']\n",
    "    win_ids_loaded = npzfiles['ids']\n",
    "\n",
    "print(X_loaded.shape)\n",
    "print(y_loaded.shape)\n",
    "print(y_binary_loaded.shape)\n",
    "print(win_ids_loaded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
