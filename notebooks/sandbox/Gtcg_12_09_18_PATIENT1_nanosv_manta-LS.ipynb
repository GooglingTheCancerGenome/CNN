{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trains and  tests on parts of  PATIENT1 data for Del_st, Del_end and No_sv, ground  truth nanosv_manta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependences and setting output configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/cog_bioinf/ridder/users/lsantuari/Software/miniconda2/envs/mcfly_new/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f', 'colors']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "import gzip\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['nanosv', 'nanosv_manta', 'id'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# dico = pickle.load(open(\"/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/060818/TestData_060818/NA12878/MultiLabelData/labels.pickle\", \"rb\"))\n",
    "# labels = dataset = dico[\"Mills2011_nanosv\"]\n",
    "\n",
    "dico = pickle.load(open(\"/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/060818/TestData_060818/PATIENT1/MultiLabelData/labels.pickle\", \"rb\"))\n",
    "print(dico.keys())\n",
    "labels = dataset = dico[\"nanosv_manta\"]\n",
    "\n",
    "window_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Chr1\n",
      "1:(255, 27, 200)\n",
      "Loading Chr2\n",
      "2:(298, 27, 200)\n",
      "Loading Chr3\n",
      "3:(247, 27, 200)\n",
      "Loading Chr4\n",
      "4:(305, 27, 200)\n",
      "Loading Chr5\n",
      "5:(233, 27, 200)\n",
      "Loading Chr6\n",
      "6:(248, 27, 200)\n",
      "Loading Chr7\n",
      "7:(239, 27, 200)\n",
      "Loading Chr8\n",
      "8:(210, 27, 200)\n",
      "Loading Chr9\n",
      "9:(146, 27, 200)\n",
      "Loading Chr10\n",
      "10:(164, 27, 200)\n",
      "Loading Chr11\n",
      "11:(176, 27, 200)\n",
      "Loading Chr12\n",
      "12:(176, 27, 200)\n",
      "Loading Chr13\n",
      "13:(133, 27, 200)\n",
      "Loading Chr14\n",
      "14:(105, 27, 200)\n",
      "Loading Chr15\n",
      "15:(84, 27, 200)\n",
      "Loading Chr16\n",
      "16:(91, 27, 200)\n",
      "Loading Chr17\n",
      "17:(91, 27, 200)\n",
      "Loading Chr18\n",
      "18:(105, 27, 200)\n",
      "Loading Chr19\n",
      "19:(71, 27, 200)\n",
      "Loading Chr20\n",
      "20:(45, 27, 200)\n",
      "Loading Chr21\n",
      "21:(61, 27, 200)\n",
      "Loading Chr22\n",
      "22:(55, 27, 200)\n"
     ]
    }
   ],
   "source": [
    "#datapath = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/060818/TestData_060818/NA12878' \n",
    "datapath = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/060818/TestData_060818/PATIENT1/'\n",
    "\n",
    "germline_1_datapath = datapath + '/ChannelData/'\n",
    "ger_1_labels_datapath = datapath + '/LabelData/'\n",
    "\n",
    "G1_data_SV = np.empty([0, 27, window_size])\n",
    "G1_labels_SV =[]\n",
    "G1_data_noSV = np.empty([0, 27, window_size])\n",
    "G1_labels_noSV =[]\n",
    "\n",
    "for i in range(1,23,1):\n",
    "        print('Loading Chr'+str(i))\n",
    "        data_file = germline_1_datapath + str(i) +'_channel_maker_real_germline.npy.gz'\n",
    "        with gzip.GzipFile(data_file, \"rb\") as f:\n",
    "            G1_data_new = np.load(f)\n",
    "        f.close()\n",
    "    \n",
    "        #G1_labels_new = np.load(ger_1_labels_datapath  +  str(i) +'_label_ci_full_overlap.npy/' +str(i) +'_label_ci_full_overlap.npy') \n",
    "        G1_labels_new = np.array(labels[str(i)])\n",
    "        # print(G1_labels_new[0])\n",
    "        G1_data_new = G1_data_new[np.where(G1_labels_new != 'UK')]\n",
    "        G1_labels_new = G1_labels_new[np.where(G1_labels_new != 'UK')]\n",
    "        G1_data_SV_new  = G1_data_new[np.where(G1_labels_new != 'noSV')]\n",
    "        G1_labels_SV_new  = G1_labels_new[np.where(G1_labels_new != 'noSV')]\n",
    "        n_windows_sv = G1_data_SV_new.shape[0]\n",
    "        G1_data_noSV_new  = G1_data_new[np.where(G1_labels_new == 'noSV')]\n",
    "        G1_labels_noSV_new  = G1_labels_new[np.where(G1_labels_new == 'noSV')]\n",
    "        G1_data_noSV_new =  G1_data_noSV_new[0:n_windows_sv]\n",
    "        G1_labels_noSV_new =  G1_labels_noSV_new[0:n_windows_sv]\n",
    "        print(str(i) + ':' + str(G1_data_SV_new.shape))\n",
    "        # print(G1_labels_SV_new[0])\n",
    "        G1_data_SV = np.concatenate((G1_data_SV, G1_data_SV_new))\n",
    "        G1_labels_SV = np.concatenate((G1_labels_SV, G1_labels_SV_new))\n",
    "        G1_data_noSV = np.concatenate((G1_data_noSV, G1_data_noSV_new))\n",
    "        G1_labels_noSV = np.concatenate((G1_labels_noSV, G1_labels_noSV_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find  the indexes that split the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_splitting_indices(labels):\n",
    "    for i in range (0, labels.shape[0] - 1):\n",
    "        if (labels[i] != labels[i+1]):\n",
    "            print(i , ': ', labels[i] , labels[i+1] )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_splitting_indices(G1_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G1_labels_SV = ['DEL'] * G1_labels_SV.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv=G1_data_SV.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3538"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1769"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(sv/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_data_noSV  = G1_data_noSV[0:int(sv/2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_labels_noSV  = G1_labels_noSV[0:int(sv/2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "SV_train = 1600\n",
    "noSV_train = 800\n",
    "SV_val = 350\n",
    "noSV_val = 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((G1_data_SV[0:SV_train], G1_data_noSV[0:noSV_train ]))\n",
    "X_val = np.concatenate((G1_data_SV[SV_train:SV_train+SV_val], G1_data_noSV[noSV_train:noSV_train +noSV_val ]))\n",
    "X_test = np.concatenate((G1_data_SV[SV_train+SV_val:], G1_data_noSV[noSV_train +noSV_val:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((G1_labels_SV[0:SV_train], G1_labels_noSV[0:noSV_train ]))\n",
    "y_val = np.concatenate((G1_labels_SV[SV_train:SV_train+SV_val], G1_labels_noSV[noSV_train:noSV_train +noSV_val ]))\n",
    "y_test = np.concatenate((G1_labels_SV[SV_train+SV_val:], G1_labels_noSV[noSV_train +noSV_val:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of training, validation and test windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 27, 200)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525, 27, 200)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2382, 27, 200)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2382,)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_channels = X_train.shape[1]\n",
    "number_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data using the reads coverage as parameter and remove uninteresting channels for deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.0"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage = np.median(X_train[:, 0, :]) #the median of the coverage in the normal cells\n",
    "coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):       \n",
    "    for i in range (0, len(X)):                              \n",
    "        for j in range(0,number_channels):                                                                                            \n",
    "            X[i][j] = np.divide(X[i][j], coverage)*100 \n",
    "# normalize(X_train)\n",
    "# normalize(X_val)\n",
    "# normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_noise_chanels(X):\n",
    "    return np.delete(X, [4-1,5-1,6-1,7-1,8-1,9-1,10-1,12-1,13-1,15-1,16-1, 17-1,18-1,19-1,23-1,24-1,26-1,27-1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_distance_chanels(X):\n",
    "    return np.delete(X, [3,4,7,8], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = eliminate_noise_chanels(X_train)\n",
    "X_val = eliminate_noise_chanels(X_val)\n",
    "X_test = eliminate_noise_chanels(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = eliminate_distance_chanels(X_train)\n",
    "X_val = eliminate_distance_chanels(X_val)\n",
    "X_test = eliminate_distance_chanels(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 5, 200)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_channels = X_train.shape[1]\n",
    "number_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiate the time series for a zero mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiate(X):\n",
    "    for i in range(0, X.shape[0]):        \n",
    "        for j in range(0, X.shape[1]):\n",
    "            for k in range(0, X.shape[2]-1):\n",
    "                X[i][j][k] = X[i][j][k+1] - X[i][j][k]\n",
    "    return X[:,:,:-1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = differentiate(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val = differentiate(X_val)\n",
    "# X_test = differentiate(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots several  windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_windows = 100\n",
    "label = [\"None\"] * number_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[0] = \"germline:coverage\"\n",
    "label[1] = \"germline:#left clipped reads\"\n",
    "label[2] = \"germline:#right clipped reads\"\n",
    "label[3] = \"germline:#split reads right split\"\n",
    "label[4] = \"germline:#split reads left split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors =['b','g', 'm', 'gray', 'r','c', 'darkgreen' ,'y', 'k', 'orange', 'gray']\n",
    "\n",
    "def plot_channels(start_window, n_windows):\n",
    "    for i in range (start_window, start_window + n_windows, 1):\n",
    "        if y_test[i] == labels[predicted[i]]:\n",
    "            continue\n",
    "        #print(y_train[i], 'id:', i)\n",
    "        print('id:', i)\n",
    "        print('Nanopore:', y_test[i], '. DeepSV:', labels[predicted[i]])\n",
    "        for j in range (0, number_channels):   \n",
    "            shift = 0\n",
    "            start =0\n",
    "            if j in [0,11]:\n",
    "                shift = -100\n",
    "            if j > 8:\n",
    "                start = -60\n",
    "            Z = [start + shift + 300 + x - 5*j*4 for x in X_test[i][j]]  \n",
    "            plt.ylim([150,450])\n",
    "            if np.max(Z) > 1000:\n",
    "                plt.ylim([-200,1000])\n",
    "                Z = [start + shift + 300 + x - 5*j*4 - 400 for x in X_test[i][j]]  \n",
    "            if j>8:\n",
    "                plt.plot(Z,  label = label[j], linestyle=':', linewidth=1.5, color = colors[j % 9])\n",
    "            else:\n",
    "                plt.plot(Z,  label = label[j], color = colors[j])\n",
    "        \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., prop={'size': 10})    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_window = 0\n",
    "n_windows = 573\n",
    "# plot_channels(start_window, n_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_windows = 50\n",
    "start_window = 500\n",
    "# plot_channels(start_window, n_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "## Transposes every window in X, to comply to McFly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2382, 200, 5)\n"
     ]
    }
   ],
   "source": [
    "def transposeDataset(X):\n",
    "    image = []\n",
    "    for i in range (0, len(X -1)):\n",
    "        tr = X[i].transpose()\n",
    "        image.append(tr)\n",
    "    return np.array(image)\n",
    "\n",
    "image1 = transposeDataset(X_train)\n",
    "image2 = transposeDataset(X_val)\n",
    "image3 = transposeDataset(X_test)\n",
    "X_train = image1\n",
    "X_val = image2\n",
    "X_test = image3\n",
    "\n",
    "n_channels = len(X_train[0][0])\n",
    "#print(len(X_test[0][0]))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the labels in McFly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DEL_start': 1, 'DEL_end': 0, 'noSV': 2}\n"
     ]
    }
   ],
   "source": [
    "mapclasses = {'DEL_start': 1, 'DEL_end': 0,  'noSV': 2}\n",
    "print(mapclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array([mapclasses[c] for c in y_train], dtype='int')\n",
    "y_val = np.array([mapclasses[c] for c in y_val], dtype='int')\n",
    "y_test = np.array([mapclasses[c] for c in y_test], dtype='int')\n",
    "y_train_binary = to_categorical(y_train)\n",
    "y_val_binary = to_categorical(y_val)\n",
    "y_test_binary = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 200, 5)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generate and train neural networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from mcfly import modelgen, find_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 321\n",
    "num_classes = y_train_binary.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "models = modelgen.generate_models(X_train.shape,\n",
    "                                  num_classes,\n",
    "                                  number_of_models = 1,\n",
    "                                  model_type = 'CNN',\n",
    "                                  cnn_min_layers=1,\n",
    "                                  cnn_max_layers=1,\n",
    "                                  cnn_min_filters = 3, \n",
    "                                  cnn_max_filters = 3, \n",
    "                                  cnn_min_fc_nodes=2, \n",
    "                                  cnn_max_fc_nodes=2,\n",
    "                                  low_lr=1.73, high_lr=1.73,\n",
    "                                  kernel_size = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 602 ms, sys: 6.92 ms, total: 609 ms\n",
      "Wall time: 608 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = modelgen.generate_models(X_train.shape,\n",
    "                                  num_classes,\n",
    "                                  number_of_models = 1,\n",
    "                                  model_type = 'CNN',\n",
    "                                  cnn_min_layers=2,\n",
    "                                  cnn_max_layers=2,\n",
    "                                  cnn_min_filters = 4, \n",
    "                                  cnn_max_filters = 4, \n",
    "                                  cnn_min_fc_nodes=6, \n",
    "                                  cnn_max_fc_nodes=6,\n",
    "                                  low_lr=2, high_lr=2)\n",
    "                                  #kernel_size = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0\n",
      "{'learning_rate': 0.01, 'regularization_rate': 0.010014443502238768, 'filters': array([4, 4]), 'fc_hidden_nodes': 6}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_25 (Batc (None, 200, 5)            20        \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 200, 4)            64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 200, 4)            16        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 200, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 200, 4)            52        \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 200, 4)            16        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 200, 4)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 4806      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 5,007\n",
      "Trainable params: 4,975\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "CPU times: user 2.42 ms, sys: 0 ns, total: 2.42 ms\n",
      "Wall time: 1.97 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i=0\n",
    "for model, params, model_types in models:\n",
    "    print('model ' + str(i))\n",
    "    i=i+1\n",
    "    print(params)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_size = X_train.shape[0]\n",
    "train_set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 CNN\n",
      "Train on 2400 samples, validate on 525 samples\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 4s 2ms/step - loss: 0.6152 - acc: 0.8487 - val_loss: 0.7022 - val_acc: 0.7581\n",
      "CPU times: user 6.38 s, sys: 315 ms, total: 6.69 s\n",
      "Wall time: 5.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "histories, val_accuracies, val_losses = find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                                 X_val, y_val_binary,\n",
    "                                                                                 models,nr_epochs=1, \n",
    "                                                                                 subset_size=train_set_size,\n",
    "                                                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 CNN {'learning_rate': 0.01, 'regularization_rate': 0.010014443502238768, 'filters': array([4, 4]), 'fc_hidden_nodes': 6}\n"
     ]
    }
   ],
   "source": [
    "best_model_index = np.argmax(val_accuracies)\n",
    "best_model, best_params, best_model_types = models[best_model_index]\n",
    "print(best_model_index, best_model_types, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = os.path.join('/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/060818/TestData_060818/NA12878/ModelData', 'Gtcg_13_9')\n",
    "\n",
    "best_model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best model on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2400 samples, validate on 525 samples\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 1s 380us/step - loss: 0.3951 - acc: 0.9004 - val_loss: 1.3592 - val_acc: 0.3524\n"
     ]
    }
   ],
   "source": [
    "#We make a copy of the model, to start training from fresh\n",
    "nr_epochs = 1\n",
    "datasize = train_set_size # Change in `X_train.shape[0]` if training complete data set\n",
    "history = best_model.fit(X_train[:datasize,:,:], y_train_binary[:datasize,:],\n",
    "              epochs=nr_epochs, validation_data=(X_val, y_val_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "model_path = os.path.join('/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/060818/TestData_060818/NA12878/ModelData',  'Gtcg_13_9')\n",
    "model_reloaded = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect model predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = model_reloaded \n",
    "datasize = X_test.shape[0]\n",
    "probs = model.predict_proba(X_test[:datasize,:,:],batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns are predicted labels by DeepSV, rows are nanopore labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DEL_end', 0), ('DEL_start', 1), ('noSV', 2)]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapclasses = {'DEL_end': 0, 'DEL_start': 1, 'noSV': 2}\n",
    "dict=mapclasses\n",
    "dict_sorted = sorted(dict.items(), key=lambda x: x[1])\n",
    "dict_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i[0] for i in dict_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEL_end</th>\n",
       "      <th>DEL_start</th>\n",
       "      <th>noSV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DEL_end</th>\n",
       "      <td>550</td>\n",
       "      <td>2</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEL_start</th>\n",
       "      <td>10</td>\n",
       "      <td>377</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noSV</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DEL_end  DEL_start  noSV\n",
       "DEL_end        550          2   253\n",
       "DEL_start       10        377   396\n",
       "noSV             7          7   780"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "predicted = probs.argmax(axis=1)\n",
    "y_index = y_test_binary.argmax(axis=1)\n",
    "confusion_matrix = pd.crosstab(pd.Series(y_index), pd.Series(predicted))\n",
    "confusion_matrix.index = [labels[i] for i in confusion_matrix.index]\n",
    "confusion_matrix.columns = [labels[i] for i in confusion_matrix.columns]\n",
    "confusion_matrix.reindex(columns=[l for l in labels], fill_value=0)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best current model on testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss and accuracy of best model: [0.7951599833446826, 0.716624685138539]\n",
      "CPU times: user 1.22 s, sys: 55.4 ms, total: 1.28 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_test = model.evaluate(X_test, y_test_binary, verbose=False)\n",
    "print('Test loss and accuracy of best model: ' + str(score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    iteration      label  precision  recall          F1\n",
      "0    0.333333    DEL_end       39.0    32.0   35.154930\n",
      "0    0.333333  DEL_start       37.0    25.0   29.838710\n",
      "0    0.333333       noSV       40.0    59.0   47.676768\n",
      "0    0.346667    DEL_end       39.0    32.0   35.154930\n",
      "0    0.346667  DEL_start       38.0    25.0   30.158730\n",
      "0    0.346667       noSV       42.0    64.0   50.716981\n",
      "0    0.360000    DEL_end       38.0    30.0   33.529412\n",
      "0    0.360000  DEL_start       37.0    23.0   28.366667\n",
      "0    0.360000       noSV       44.0    70.0   54.035088\n",
      "0    0.373333    DEL_end       39.0    30.0   33.913043\n",
      "0    0.373333  DEL_start       41.0    24.0   30.276923\n",
      "0    0.373333       noSV       47.0    78.0   58.656000\n",
      "0    0.386667    DEL_end       45.0    34.0   38.734177\n",
      "0    0.386667  DEL_start       43.0    24.0   30.805970\n",
      "0    0.386667       noSV       50.0    84.0   62.686567\n",
      "0    0.400000    DEL_end       44.0    33.0   37.714286\n",
      "0    0.400000  DEL_start       42.0    22.0   28.875000\n",
      "0    0.400000       noSV       51.0    89.0   64.842857\n",
      "0    0.413333    DEL_end       48.0    36.0   41.142857\n",
      "0    0.413333  DEL_start       46.0    22.0   29.764706\n",
      "0    0.413333       noSV       53.0    94.0   67.782313\n",
      "0    0.426667    DEL_end       52.0    38.0   43.911111\n",
      "0    0.426667  DEL_start       48.0    22.0   30.171429\n",
      "0    0.426667       noSV       54.0    98.0   69.631579\n",
      "0    0.440000    DEL_end       51.0    36.0   42.206897\n",
      "0    0.440000  DEL_start       48.0    20.0   28.235294\n",
      "0    0.440000       noSV       49.0    98.0   65.333333\n",
      "0    0.453333    DEL_end       49.0    34.0   40.144578\n",
      "0    0.453333  DEL_start       45.0    17.0   24.677419\n",
      "0    0.453333       noSV       45.0    98.0   61.678322\n",
      "..        ...        ...        ...     ...         ...\n",
      "0    0.786667    DEL_end       51.0    54.0   52.457143\n",
      "0    0.786667  DEL_start       50.0     3.0    5.660377\n",
      "0    0.800000    DEL_end       51.0    58.0   54.275229\n",
      "0    0.800000  DEL_start       67.0     4.0    7.549296\n",
      "0    0.813333    DEL_end       50.0    55.0   52.380952\n",
      "0    0.813333  DEL_start       50.0     3.0    5.660377\n",
      "0    0.826667    DEL_end       50.0    59.0   54.128440\n",
      "0    0.826667  DEL_start       50.0     3.0    5.660377\n",
      "0    0.840000    DEL_end       49.0    62.0   54.738739\n",
      "0    0.840000  DEL_start      100.0     3.0    5.825243\n",
      "0    0.853333    DEL_end       50.0    59.0   54.128440\n",
      "0    0.853333  DEL_start      100.0     2.0    3.921569\n",
      "0    0.866667    DEL_end       51.0    65.0   57.155172\n",
      "0    0.866667  DEL_start        0.0     0.0         NaN\n",
      "0    0.880000    DEL_end       60.0    72.0   65.454545\n",
      "0    0.880000  DEL_start      100.0     4.0    7.692308\n",
      "0    0.893333    DEL_end       60.0    56.0   57.931034\n",
      "0    0.893333  DEL_start        0.0     0.0         NaN\n",
      "0    0.906667    DEL_end       67.0    67.0   67.000000\n",
      "0    0.906667  DEL_start        0.0     0.0         NaN\n",
      "0    0.920000    DEL_end       60.0    75.0   66.666667\n",
      "0    0.920000  DEL_start        0.0     0.0         NaN\n",
      "0    0.933333    DEL_end       67.0    67.0   67.000000\n",
      "0    0.933333  DEL_start        0.0     0.0         NaN\n",
      "0    0.946667    DEL_end      100.0   100.0  100.000000\n",
      "0    0.946667  DEL_start      100.0   100.0  100.000000\n",
      "0    0.960000    DEL_end        0.0     0.0         NaN\n",
      "0    0.960000  DEL_start        0.0     0.0         NaN\n",
      "0    0.973333    DEL_end      100.0   100.0  100.000000\n",
      "0    0.986667    DEL_end      100.0   100.0  100.000000\n",
      "\n",
      "[115 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/cog_bioinf/ridder/users/lsantuari/Software/miniconda2/envs/mcfly_new/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "df_conf = pd.DataFrame()\n",
    "\n",
    "for i in np.linspace(1.0 / len(labels), 1, num=50, endpoint=False):\n",
    "\n",
    "    predicted = np.argwhere(probs > i)[:, 1]\n",
    "    y_index = np.argwhere(y_test_binary > i)[:, 1]\n",
    "\n",
    "    # Rows: true, columns: predicted\n",
    "    confusion_matrix = pd.crosstab(pd.Series(y_index), pd.Series(predicted))\n",
    "    confusion_matrix.index = [labels[i] for i in confusion_matrix.index]\n",
    "    confusion_matrix.columns = [labels[i] for i in confusion_matrix.columns]\n",
    "    confusion_matrix.reindex(columns=[l for l in labels], fill_value=0)\n",
    "\n",
    "    #print('Confusion matrix:')\n",
    "    #print(confusion_matrix)\n",
    "    \n",
    "    for l in labels:\n",
    "        if l in confusion_matrix.index:\n",
    "            # print(confusion_matrix.loc[l,:])\n",
    "            # print(confusion_matrix.loc[:,l])\n",
    "\n",
    "            # label_correct = confusion_matrix.loc[l, l]\n",
    "            label_precision = np.around(confusion_matrix.loc[l, l] / sum(confusion_matrix.loc[:, l]) * 100)\n",
    "            label_recall = np.around(confusion_matrix.loc[l, l] / sum(confusion_matrix.loc[l, :]) * 100)\n",
    "            label_F1 = 2 * (label_precision * label_recall) / (label_precision + label_recall)\n",
    "\n",
    "            # print(f'Iter:{i} {l} -> Precision:{label_precision}%, Recall:{label_recall}%, F1:{label_F1}')\n",
    "\n",
    "            df_intres = pd.DataFrame(\n",
    "                {'iteration': [i], 'label': [l],\n",
    "                 'precision': [label_precision], 'recall': [label_recall], 'F1': [label_F1]})\n",
    "            df_conf = df_conf.append(df_intres)\n",
    "            \n",
    "print(df_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_conf[df_conf['label']=='DEL_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(df_conf[df_conf['label']=='DEL_start']['precision'], df_conf[df_conf['label']=='DEL_start']['recall'])\n",
    "#plt.ylabel('some numbers')\n",
    "#plt.show()\n",
    "\n",
    "#print(df_conf[df_conf['label']=='DEL_start']['precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
