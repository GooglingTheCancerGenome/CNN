{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save a channel and label data for the NA12878 sample with the Mills2011_nanosv labels, for Chr[1,2,3]\n",
    "## This dataset is used as a reference test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "import gzip\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "def transposeDataset(X):\n",
    "    image = []\n",
    "    for i in range (0, len(X -1)):\n",
    "        tr = X[i].transpose()\n",
    "        image.append(tr)\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39450, 29, 200)\n",
      "(39450,)\n"
     ]
    }
   ],
   "source": [
    "date = '270219'\n",
    "\n",
    "art_training_data = []\n",
    "art_training_labels = []\n",
    "\n",
    "base_dir = os.path.join('/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test',\n",
    "                        date, 'TrainingData_'+date)\n",
    "\n",
    "svtype = 'INDEL'\n",
    "sample = 'G1'\n",
    "\n",
    "for svtype in ['INDEL', 'INDEL_HOM']:\n",
    "\n",
    "    datapath = os.path.join(base_dir, svtype, sample)\n",
    "    data_file = os.path.join(datapath, 'ChannelData', sample+'.npy.gz')\n",
    "    label_file = os.path.join(datapath, 'LabelData', sample+'_17_label.npy.gz')\n",
    "\n",
    "    with gzip.GzipFile(data_file, \"rb\") as f:\n",
    "        data_mat = np.load(f)\n",
    "        art_training_data.extend(data_mat)\n",
    "    f.close()\n",
    "\n",
    "    with gzip.GzipFile(label_file, \"rb\") as f:\n",
    "        label_list = np.load(f)\n",
    "        art_training_labels.extend(label_list)\n",
    "    f.close()\n",
    "\n",
    "art_training_data = np.array(art_training_data)\n",
    "art_training_labels = np.array(art_training_labels)\n",
    "\n",
    "assert len(art_training_data) == len(art_training_labels)\n",
    "\n",
    "print(art_training_data.shape)\n",
    "print(art_training_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = 'NA12878'\n",
    "#date = '231118'\n",
    "date = '270219'\n",
    "label_type = 'Mills2011_nanosv'\n",
    "\n",
    "# Load label dictionary\n",
    "dico_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData_'+date+'/'+sample_name+'/MultiLabelData/labels.pickle.gz'\n",
    "with gzip.GzipFile(dico_file, \"rb\") as f:\n",
    "    dico = np.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X']\n",
      "Loading data for Chr4\n",
      "Loading data for Chr5\n",
      "Loading data for Chr6\n",
      "Loading data for Chr7\n",
      "Loading data for Chr8\n",
      "Loading data for Chr9\n",
      "Loading data for Chr10\n",
      "Loading data for Chr11\n",
      "Loading data for Chr12\n",
      "Loading data for Chr13\n",
      "Loading data for Chr14\n",
      "Loading data for Chr15\n",
      "Loading data for Chr16\n",
      "Loading data for Chr17\n",
      "Loading data for Chr18\n",
      "Loading data for Chr19\n",
      "Loading data for Chr20\n",
      "Loading data for Chr21\n",
      "Loading data for Chr22\n",
      "Loading data for ChrX\n",
      "Counter({'noSV': 934333, 'UK': 1231, 'DEL_start': 904, 'DEL_end': 823})\n"
     ]
    }
   ],
   "source": [
    "# Create reference test set using Chr4 to ChrX\n",
    "\n",
    "#Leaving out chromosome Y and MT for the moment\n",
    "chr_list = list(map(str, np.arange(4,23)))\n",
    "chr_list.append('X')\n",
    "\n",
    "print(chr_list)\n",
    "\n",
    "training_data = []\n",
    "training_labels = []\n",
    "training_id = []\n",
    "\n",
    "datapath = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData_'+date+'/'+sample_name+'/ChannelData/'\n",
    "\n",
    "for i in chr_list:\n",
    "    \n",
    "    print('Loading data for Chr%s' % i)\n",
    "    data_file = datapath + sample_name + '_' + str(i) + '.npy.gz'\n",
    "    with gzip.GzipFile(data_file, \"rb\") as f:\n",
    "        data_mat = np.load(f)\n",
    "        training_data.extend(data_mat)\n",
    "    f.close()\n",
    "    \n",
    "    training_labels.extend(dico[label_type][i])\n",
    "    training_id.extend([d['chromosome']+'_'+str(d['position']) for d in dico['id'][i]])\n",
    "    \n",
    "print(Counter(training_labels))\n",
    "assert len(training_data) == len(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(training_data)\n",
    "training_labels = np.array(training_labels)\n",
    "training_id = np.array(training_id)\n",
    "\n",
    "# Remove windows labelled as unknown ('UK')\n",
    "keep = np.where(np.array(training_labels)!='UK')\n",
    "training_data = training_data[keep]\n",
    "training_labels = training_labels[keep]\n",
    "training_id = training_id[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'noSV': 934333, 'DEL_start': 904, 'DEL_end': 823})\n",
      "Minimum number of labels = 823\n",
      "Counter({'noSV': 823, 'DEL_end': 823, 'DEL_start': 823})\n"
     ]
    }
   ],
   "source": [
    "cnt_lab = Counter(training_labels)\n",
    "min_v = min([v for k, v in cnt_lab.items()])\n",
    "print(cnt_lab)\n",
    "print('Minimum number of labels = ' + str(min_v))\n",
    "\n",
    "data_balanced = []\n",
    "labels_balanced = []\n",
    "id_balanced = []\n",
    "\n",
    "for l in cnt_lab.keys():\n",
    "    #print(l)\n",
    "    iw = np.where(training_labels==l)\n",
    "    ii = iw[0][:min_v]\n",
    "    data_balanced.extend(training_data[ii])\n",
    "    labels_balanced.extend(training_labels[ii])\n",
    "    id_balanced.extend(training_id[ii])\n",
    "\n",
    "print(Counter(labels_balanced))\n",
    "\n",
    "X = np.array(data_balanced)\n",
    "y = np.array(labels_balanced)\n",
    "z = np.array(id_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Remove windows with nan if present\n",
    "# print(np.where(np.isnan(X)))\n",
    "idx = np.unique(np.where(np.isnan(X))[0])\n",
    "print(idx)\n",
    "#print(X[np.where(np.isnan(X))])\n",
    "print(z[idx])\n",
    "idx = numpy.unique(np.where(np.isnan(X))[0])\n",
    "X = np.delete(X, idx, 0)\n",
    "y = np.delete(y, idx, 0)\n",
    "z = np.delete(z, idx, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GC track seems fine at positions Chr4_1423148 and Chr4_1478645\n",
    "\n",
    "# import pyBigWig\n",
    "\n",
    "# bw_gc = pyBigWig.open(\"/hpc/cog_bioinf/ridder/users/lsantuari/Datasets/UCSC/hg19/hg19.gc5Base.bw\")\n",
    "\n",
    "# print(bw_gc.chroms())\n",
    "# for loc in z[idx]:\n",
    "    \n",
    "#     chr_pos = loc.split('_')\n",
    "#     chrName = chr_pos[0]\n",
    "#     mid_pos = int(chr_pos[1])\n",
    "#     win = 200\n",
    "#     start_win = mid_pos-int(win/2)\n",
    "#     end_win = mid_pos+int(win/2)\n",
    "    \n",
    "#     gc_array = bw_gc.values('chr' + chrName, start_win, end_win)\n",
    "    \n",
    "#     print(mid_pos)\n",
    "#     print(gc_array)\n",
    "#     print(len(gc_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transposeDataset(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapclasses = {'DEL_start': 1, 'DEL_end': 0,  'noSV': 2}\n",
    "y_num = np.array([mapclasses[c] for c in y], dtype='int')\n",
    "y_binary = to_categorical(y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2469, 200, 29)\n",
      "(2469,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save channels and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.64 ms, sys: 703 ms, total: 711 ms\n",
      "Wall time: 2.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import errno\n",
    "\n",
    "datapath_training=os.path.join(datapath,'../TrainingData/balanced_r')\n",
    "\n",
    "try:\n",
    "    os.makedirs(datapath_training, exist_ok=True)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "data_output_file = os.path.join(datapath_training, sample_name + '_' + label_type + '_channels.npy')\n",
    "np.save(data_output_file, X)\n",
    "os.system('gzip '+data_output_file)\n",
    "\n",
    "label_output_file = os.path.join(datapath_training, sample_name + '_' + label_type + '_labels.npy')\n",
    "np.save(label_output_file, y)\n",
    "os.system('gzip '+label_output_file)\n",
    "\n",
    "label_output_file = os.path.join(datapath_training, sample_name + '_' + label_type + '_labels_binary.npy')\n",
    "np.save(label_output_file, y_binary)\n",
    "os.system('gzip '+label_output_file)\n",
    "\n",
    "id_output_file = os.path.join(datapath_training, sample_name + '_' + label_type + '_ids.npy')\n",
    "np.save(id_output_file, z)\n",
    "os.system('gzip '+id_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2469, 200, 29)\n",
      "(2469,)\n",
      "(2469,)\n",
      "(2469,)\n"
     ]
    }
   ],
   "source": [
    "data_output_file = os.path.join(datapath_training, sample_name + '_' + label_type + '_channels.npy.gz')\n",
    "with gzip.GzipFile(data_output_file, \"rb\") as f:\n",
    "    X = np.load(f)\n",
    "\n",
    "label_output_file = os.path.join(datapath_training, sample_name + '_' + label_type + '_labels.npy.gz')\n",
    "with gzip.GzipFile(label_output_file, \"rb\") as f:\n",
    "    y = np.load(f)\n",
    "f.close()\n",
    "\n",
    "label_output_file = os.path.join(datapath_training, sample_name + '_' + label_type + '_labels_binary.npy.gz')\n",
    "with gzip.GzipFile(label_output_file, \"rb\") as f:\n",
    "    y_binary = np.load(f)\n",
    "f.close()\n",
    "\n",
    "id_output_file = os.path.join(datapath_training, sample_name + '_' + label_type + '_ids.npy.gz')\n",
    "with gzip.GzipFile(id_output_file, \"rb\") as f:\n",
    "    win_ids = np.load(f)\n",
    "f.close()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(y.shape)\n",
    "print(win_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data():\n",
    "    # Create reference test set using Chr4 to ChrX\n",
    "    sample_name = 'NA12878'\n",
    "    date = '270219'\n",
    "    label_type = 'Mills2011_nanosv'\n",
    "    \n",
    "    def remove_label(training_data, training_labels, training_id, label):\n",
    "\n",
    "        # Remove windows labelled as label\n",
    "        keep = np.where(np.array(training_labels) != label)\n",
    "        training_data = training_data[keep]\n",
    "        training_labels = training_labels[keep]\n",
    "        training_id = training_id[keep]\n",
    "\n",
    "        return training_data, training_labels, training_id\n",
    "\n",
    "    def get_label_dict():\n",
    "        # Load label dictionary\n",
    "        dico_file = os.path.join('/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test',\n",
    "                                 date, 'TestData_' + date, sample_name, 'MultiLabelData/labels.pickle.gz')\n",
    "        with gzip.GzipFile(dico_file, \"rb\") as f:\n",
    "            dico = np.load(f)\n",
    "        f.close()\n",
    "\n",
    "        return dico\n",
    "\n",
    "    dico = get_label_dict()\n",
    "\n",
    "    # Leaving out chromosome Y and MT for the moment\n",
    "    #chr_list = list(map(str, np.arange(4, 23)))\n",
    "    #chr_list.append('X')\n",
    "    chr_list = ['22']\n",
    "\n",
    "    print(chr_list)\n",
    "\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    training_id = []\n",
    "\n",
    "    datapath = os.path.join('/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test',\n",
    "                             date, 'TestData_'+date, sample_name, 'ChannelData')\n",
    "\n",
    "    for i in chr_list:\n",
    "        print('Loading data for Chr%s' % i)\n",
    "        data_file = os.path.join(datapath, sample_name + '_' + str(i) + '.npy.gz')\n",
    "        with gzip.GzipFile(data_file, \"rb\") as f:\n",
    "            data_mat = np.load(f)\n",
    "            training_data.extend(data_mat)\n",
    "        f.close()\n",
    "\n",
    "        training_labels.extend(dico[label_type][i])\n",
    "        training_id.extend([d['chromosome'] + '_' + str(d['position']) for d in dico['id'][i]])\n",
    "\n",
    "    print(Counter(training_labels))\n",
    "\n",
    "    training_data = np.array(training_data)\n",
    "    training_labels = np.array(training_labels)\n",
    "    training_id = np.array(training_id)\n",
    "    \n",
    "    training_data, training_labels, training_id = remove_label(training_data,\n",
    "                                                               training_labels, training_id, label = 'UK')\n",
    "    print(Counter(training_labels))\n",
    "\n",
    "    assert len(training_data) == len(training_labels)\n",
    "\n",
    "    return training_data, training_labels, training_id\n",
    "\n",
    "\n",
    "def artificial_data():\n",
    "    \n",
    "    def remove_label(training_data, training_labels, label):\n",
    "\n",
    "        # Remove windows labelled as label\n",
    "        keep = np.where(np.array(training_labels) != label)\n",
    "        training_data = training_data[keep]\n",
    "        training_labels = training_labels[keep]\n",
    "\n",
    "        return training_data, training_labels\n",
    "\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "\n",
    "    base_dir = os.path.join('/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test',\n",
    "                            date, 'TrainingData_'+date)\n",
    "    sample = 'G1'\n",
    "\n",
    "    for svtype in ['INDEL', 'INDEL_HOM']:\n",
    "\n",
    "        datapath = os.path.join(base_dir, svtype, sample)\n",
    "        data_file = os.path.join(datapath, 'ChannelData', sample+'.npy.gz')\n",
    "        label_file = os.path.join(datapath, 'LabelData', sample+'_17_label.npy.gz')\n",
    "\n",
    "        with gzip.GzipFile(data_file, \"rb\") as f:\n",
    "            data_mat = np.load(f)\n",
    "            training_data.extend(data_mat)\n",
    "        f.close()\n",
    "\n",
    "        with gzip.GzipFile(label_file, \"rb\") as f:\n",
    "            label_list = np.load(f)\n",
    "            training_labels.extend(label_list)\n",
    "        f.close()\n",
    "\n",
    "    training_data = np.array(training_data)\n",
    "    training_labels = np.array(training_labels)\n",
    "    \n",
    "    training_data, training_labels = remove_label(training_data,\n",
    "                                                  training_labels, label = 'INS_pos')\n",
    "    print(Counter(training_labels))\n",
    "\n",
    "    assert len(training_data) == len(training_labels)\n",
    "\n",
    "    return training_data, training_labels\n",
    "\n",
    "\n",
    "def mixed_data():\n",
    "\n",
    "    def subsample_nosv(data, labels, pc, lab):\n",
    "        \n",
    "        print('subsample')\n",
    "\n",
    "        indices_label = np.where(training_labels == lab)[0]\n",
    "        print(indices_label)\n",
    "        indices_to_remove = indices_label[np.arange(int(round(len(indices_label)*pc)), len(indices_label))]\n",
    "        print(indices_to_remove)\n",
    "        X = np.delete(data, indices_to_remove)\n",
    "        y = np.delete(labels, indices_to_remove)\n",
    "\n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "        print(Counter(y))\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    real_training_data, real_training_labels, real_training_id = real_data()\n",
    "    art_training_data, art_training_labels = artificial_data()\n",
    "\n",
    "    # print('concatenare data')\n",
    "    training_data = np.concatenate((real_training_data, art_training_data), axis=0)\n",
    "    # print('concatenare labels')\n",
    "    print(real_training_labels)\n",
    "    print(art_training_labels)\n",
    "    training_labels = np.concatenate((real_training_labels, art_training_labels), axis=0)\n",
    "\n",
    "    for pc in np.linspace(0.1, 1, num=9):\n",
    "        print(pc)\n",
    "        X, y = subsample_nosv(training_data, training_labels, pc, 'noSV')\n",
    "\n",
    "        mapclasses = {'DEL_start': 1, 'DEL_end': 0, 'noSV': 2}\n",
    "        y_num = np.array([mapclasses[c] for c in y], dtype='int')\n",
    "        y_binary = to_categorical(y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22']\n",
      "Loading data for Chr22\n",
      "Counter({'noSV': 17527, 'UK': 32, 'DEL_start': 13, 'DEL_end': 9})\n",
      "Counter({'noSV': 17527, 'DEL_start': 13, 'DEL_end': 9})\n",
      "Counter({'DEL_end': 9767, 'DEL_start': 9646})\n",
      "['noSV' 'noSV' 'noSV' ... 'noSV' 'noSV' 'noSV']\n",
      "['DEL_start' 'DEL_start' 'DEL_start' ... 'DEL_end' 'DEL_end' 'DEL_end']\n",
      "0.1\n",
      "subsample\n",
      "[    0     1     2 ... 17546 17547 17548]\n",
      "[ 1757  1758  1759 ... 17546 17547 17548]\n",
      "(214363826,)\n",
      "(21188,)\n",
      "Counter({'DEL_end': 9776, 'DEL_start': 9659, 'noSV': 1753})\n",
      "0.21250000000000002\n",
      "subsample\n",
      "[    0     1     2 ... 17546 17547 17548]\n",
      "[ 3730  3731  3732 ... 17546 17547 17548]\n",
      "(214365797,)\n",
      "(23159,)\n",
      "Counter({'DEL_end': 9776, 'DEL_start': 9659, 'noSV': 3724})\n",
      "0.325\n",
      "subsample\n",
      "[    0     1     2 ... 17546 17547 17548]\n",
      "[ 5704  5705  5706 ... 17546 17547 17548]\n",
      "(214367769,)\n",
      "(25131,)\n",
      "Counter({'DEL_end': 9776, 'DEL_start': 9659, 'noSV': 5696})\n",
      "0.4375\n",
      "subsample\n",
      "[    0     1     2 ... 17546 17547 17548]\n",
      "[ 7678  7679  7680 ... 17546 17547 17548]\n",
      "(214369741,)\n",
      "(27103,)\n",
      "Counter({'DEL_end': 9776, 'DEL_start': 9659, 'noSV': 7668})\n",
      "0.55\n",
      "subsample\n",
      "[    0     1     2 ... 17546 17547 17548]\n",
      "[ 9655  9656  9657 ... 17546 17547 17548]\n",
      "(214371713,)\n",
      "(29075,)\n",
      "Counter({'DEL_end': 9776, 'DEL_start': 9659, 'noSV': 9640})\n",
      "0.6625\n",
      "subsample\n",
      "[    0     1     2 ... 17546 17547 17548]\n",
      "[11627 11628 11629 ... 17546 17547 17548]\n",
      "(214373685,)\n",
      "(31047,)\n",
      "Counter({'noSV': 11612, 'DEL_end': 9776, 'DEL_start': 9659})\n",
      "0.775\n",
      "subsample\n",
      "[    0     1     2 ... 17546 17547 17548]\n",
      "[13600 13601 13602 ... 17546 17547 17548]\n",
      "(214375656,)\n",
      "(33018,)\n",
      "Counter({'noSV': 13583, 'DEL_end': 9776, 'DEL_start': 9659})\n",
      "0.8875\n",
      "subsample\n",
      "[    0     1     2 ... 17546 17547 17548]\n",
      "[15572 15573 15574 ... 17546 17547 17548]\n",
      "(214377628,)\n",
      "(34990,)\n",
      "Counter({'noSV': 15555, 'DEL_end': 9776, 'DEL_start': 9659})\n",
      "1.0\n",
      "subsample\n",
      "[    0     1     2 ... 17546 17547 17548]\n",
      "[]\n",
      "(214379600,)\n",
      "(36962,)\n",
      "Counter({'noSV': 17527, 'DEL_end': 9776, 'DEL_start': 9659})\n"
     ]
    }
   ],
   "source": [
    "mixed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
