{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains and  tests on parts of  NA12878 data for Del_st, Del_end and No_sv, ground  truth Mills_nanosv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load dependences and setting output configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dico = pickle.load(open(\"F:/1_GTCG/data/11092018/labels.pickle/labels.pickle\", \"rb\"))\n",
    "data_labels = dataset = dico[\"Mills2011_nanosv\"]\n",
    "window_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dico = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replications = 100\n",
    "factor_nosv = 1 # factor_nosv times less Nosv than del-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noSV\n",
      "1:(222, 27, 200)\n",
      "noSV\n",
      "2:(205, 27, 200)\n",
      "noSV\n",
      "3:(208, 27, 200)\n",
      "noSV\n",
      "4:(228, 27, 200)\n",
      "noSV\n",
      "5:(214, 27, 200)\n",
      "noSV\n",
      "6:(162, 27, 200)\n",
      "noSV\n",
      "7:(163, 27, 200)\n",
      "noSV\n",
      "8:(135, 27, 200)\n",
      "noSV\n",
      "9:(127, 27, 200)\n",
      "noSV\n",
      "10:(107, 27, 200)\n",
      "noSV\n",
      "11:(119, 27, 200)\n",
      "noSV\n",
      "12:(114, 27, 200)\n",
      "noSV\n",
      "13:(106, 27, 200)\n",
      "noSV\n",
      "14:(66, 27, 200)\n",
      "noSV\n",
      "15:(61, 27, 200)\n",
      "noSV\n",
      "16:(47, 27, 200)\n",
      "noSV\n",
      "17:(48, 27, 200)\n",
      "noSV\n",
      "18:(77, 27, 200)\n",
      "noSV\n",
      "19:(44, 27, 200)\n",
      "noSV\n",
      "20:(58, 27, 200)\n",
      "noSV\n",
      "21:(28, 27, 200)\n",
      "noSV\n",
      "22:(21, 27, 200)\n"
     ]
    }
   ],
   "source": [
    "datapath = 'F:/1_GTCG/data/TestData_060818.tar/TestData_060818/NA12878' \n",
    "\n",
    "germline_1_datapath = datapath + '/ChannelData/unzipped/'\n",
    "#ger_1_labels_datapath = datapath + '/LabelData/unzipped/'\n",
    "\n",
    "G1_data_SV = np.empty([0, 27, window_size])\n",
    "G1_labels_SV =[]\n",
    "G1_data_noSV = np.empty([0, 27, window_size])\n",
    "G1_labels_noSV =[]\n",
    "total_train_sv_windows = 0\n",
    "for i in range(1,23,1):\n",
    "        G1_data_new =np.load(germline_1_datapath + str(i) + '_channel_maker_real_germline.npy/' + str(i) +'_channel_maker_real_germline.npy')\n",
    "        #G1_labels_new = np.load(ger_1_labels_datapath  +  str(i) +'_label_ci_full_overlap.npy/' +str(i) +'_label_ci_full_overlap.npy') \n",
    "        G1_labels_new = np.array(data_labels[str(i)])\n",
    "        print(G1_labels_new[0])\n",
    "        G1_data_new = G1_data_new[np.where(G1_labels_new != 'UK')]\n",
    "        G1_labels_new = G1_labels_new[np.where(G1_labels_new != 'UK')]\n",
    "        G1_data_SV_new  = G1_data_new[np.where(G1_labels_new != 'noSV')]\n",
    "        G1_labels_SV_new  = G1_labels_new[np.where(G1_labels_new != 'noSV')]\n",
    "        n_windows_sv = G1_data_SV_new.shape[0]\n",
    "        G1_data_noSV_new  = G1_data_new[np.where(G1_labels_new == 'noSV')]\n",
    "        G1_labels_noSV_new  = G1_labels_new[np.where(G1_labels_new == 'noSV')]\n",
    "        G1_data_noSV_new =  G1_data_noSV_new[0:int(replications*n_windows_sv/2/factor_nosv)]# 4 times less than del_st to boost recall\n",
    "        G1_labels_noSV_new =  G1_labels_noSV_new[0:int(replications*n_windows_sv/2/factor_nosv)] # also\n",
    "        print(str(i) + ':' + str(G1_data_SV_new.shape))\n",
    "        #print(G1_labels_SV_new[0])\n",
    "        G1_data_SV = np.concatenate((G1_data_SV, G1_data_SV_new))\n",
    "        G1_labels_SV = np.concatenate((G1_labels_SV, G1_labels_SV_new))\n",
    "        G1_data_noSV = np.concatenate((G1_data_noSV, G1_data_noSV_new))\n",
    "        G1_labels_noSV = np.concatenate((G1_labels_noSV, G1_labels_noSV_new))\n",
    "        if i < 16: #for training until chromozome 16\n",
    "            total_train_sv_windows += G1_data_SV_new.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find  the indexes that split the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_splitting_indices(labels):\n",
    "    for i in range (0, labels.shape[0] - 1):\n",
    "        if (labels[i] != labels[i+1]):\n",
    "            print(i , ': ', labels[i] , labels[i+1] )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find_splitting_indices(G1_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G1_labels_SV = ['DEL'] * G1_labels_SV.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sv=G1_data_SV.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(sv/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nosv = G1_data_noSV.shape[0]\n",
    "nosv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G1_data_noSV  = G1_data_noSV[0:2*sv] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G1_labels_noSV  = G1_labels_noSV[0:2*sv] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SV_train =  int(0.8 * total_train_sv_windows)\n",
    "noSV_train = int(replications * SV_train / 2/factor_nosv)\n",
    "SV_val = total_train_sv_windows - SV_train\n",
    "noSV_val = int(replications * SV_val / 2/factor_nosv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replicate(data, start, end, howmanytimes): \n",
    "    X = data[start:end]\n",
    "    for i in range(0,howmanytimes):\n",
    "        X = np.concatenate((X, data[start:end]))\n",
    "    return X    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = replicate(G1_data_SV, 0, SV_train, replications)\n",
    "y_train = replicate(G1_labels_SV, 0, SV_train,replications)\n",
    "X_val = replicate(G1_data_SV, SV_train, SV_train+SV_val, replications)\n",
    "y_val = replicate(G1_labels_SV, SV_train, SV_train+SV_val, replications)\n",
    "X_test = replicate(G1_data_SV, SV_train+SV_val, len(G1_data_SV), replications)\n",
    "y_test = replicate(G1_labels_SV, SV_train+SV_val, len(G1_labels_SV), replications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0857283d0448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG1_data_noSV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnoSV_train\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG1_data_noSV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnoSV_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnoSV_train\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mnoSV_val\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG1_data_noSV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnoSV_train\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mnoSV_val\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((X_train, G1_data_noSV[0:noSV_train ]))\n",
    "X_val = np.concatenate((X_val, G1_data_noSV[noSV_train:noSV_train +noSV_val ]))\n",
    "X_test = np.concatenate((X_test, G1_data_noSV[noSV_train +noSV_val:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_train, G1_labels_noSV[0:noSV_train ]))\n",
    "y_val = np.concatenate((y_val, G1_labels_noSV[noSV_train:noSV_train +noSV_val ]))\n",
    "y_test = np.concatenate((y_test, G1_labels_noSV[noSV_train +noSV_val:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1_data_noSV = []\n",
    "G1_labels_noSV = []\n",
    "G1_data_SV = []\n",
    "G1_labels_SV = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of training, validation and test windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_channels = X_train.shape[1]\n",
    "number_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data using the reads coverage as parameter and remove uninteresting channels for deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coverage = np.median(X_train[:, 0, :]) #the median of the coverage in the normal cells\n",
    "coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize(X):       \n",
    "    for i in range (0, len(X)):                              \n",
    "        for j in range(0,number_channels):                                                                                            \n",
    "            X[i][j] = np.divide(X[i][j], coverage)*100 \n",
    "normalize(X_train)\n",
    "normalize(X_val)\n",
    "normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eliminate_noise_chanels(X):\n",
    "    return np.delete(X, [4-1,5-1,6-1,7-1,8-1,9-1,10-1,12-1,13-1,15-1,16-1, 17-1,18-1,19-1,23-1,24-1,26-1,27-1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eliminate_distance_chanels(X):\n",
    "    return np.delete(X, [3,4,7,8], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = eliminate_noise_chanels(X_train)\n",
    "X_val = eliminate_noise_chanels(X_val)\n",
    "X_test = eliminate_noise_chanels(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = eliminate_distance_chanels(X_train)\n",
    "X_val = eliminate_distance_chanels(X_val)\n",
    "X_test = eliminate_distance_chanels(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "number_channels = X_train.shape[1]\n",
    "number_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiate the time series for a zero mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def differentiate(X):\n",
    "    for i in range(0, X.shape[0]):        \n",
    "        for j in range(0, X.shape[1]):\n",
    "            for k in range(0, X.shape[2]-1):\n",
    "                X[i][j][k] = X[i][j][k+1] - X[i][j][k]\n",
    "    return X[:,:,:-1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train = differentiate(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_val = differentiate(X_val)\n",
    "#X_test = differentiate(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots several  windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_windows = 100\n",
    "label = [\"None\"] * number_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label[0] = \"germline:coverage\"\n",
    "label[1] = \"germline:#left clipped reads\"\n",
    "label[2] = \"germline:#right clipped reads\"\n",
    "label[3] = \"germline:#split reads right split\"\n",
    "label[4] = \"germline:#split reads left split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors =['b','g', 'm', 'gray', 'r','c', 'darkgreen' ,'y', 'k', 'orange', 'gray']\n",
    "\n",
    "def plot_channels(start_window, n_windows):\n",
    "    for i in range (start_window, start_window + n_windows, 1):\n",
    "        #if y_test[i] == labels[predicted[i]]:\n",
    "            #continue\n",
    "        #print(y_train[i], 'id:', i)\n",
    "        print('id:', i)\n",
    "        print('Label:', y_test[i])#, '. DeepSV:', labels[predicted[i]])\n",
    "        for j in range (0, number_channels):   \n",
    "            shift = 0\n",
    "            start =0\n",
    "            if j in [0,11]:\n",
    "                shift = -100\n",
    "            if j > 8:\n",
    "                start = -60\n",
    "            Z = [start + shift + 300 + x - 5*j*4 for x in X_test[i][j]]  \n",
    "            plt.ylim([150,450])\n",
    "            if np.max(Z) > 1000:\n",
    "                plt.ylim([-200,1000])\n",
    "                Z = [start + shift + 300 + x - 5*j*4 - 400 for x in X_test[i][j]]  \n",
    "            if j>8:\n",
    "                plt.plot(Z,  label = label[j], linestyle=':', linewidth=1.5, color = colors[j % 9])\n",
    "            else:\n",
    "                plt.plot(Z,  label = label[j], color = colors[j])\n",
    "        \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., prop={'size': 10})    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_window = 0\n",
    "n_windows = 57\n",
    "plot_channels(start_window, n_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_windows = 50\n",
    "start_window = 500\n",
    "plot_channels(start_window, n_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "## Transposes every window in X, to comply to McFly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transposeDataset(X):\n",
    "    image = []\n",
    "    for i in range (0, len(X -1)):\n",
    "        tr = X[i].transpose()\n",
    "        image.append(tr)\n",
    "    return np.array(image)\n",
    "\n",
    "image1 = transposeDataset(X_train)\n",
    "image2 = transposeDataset(X_val)\n",
    "image3 = transposeDataset(X_test)\n",
    "X_train = image1\n",
    "X_val = image2\n",
    "X_test = image3\n",
    "\n",
    "n_channels = len(X_train[0][0])\n",
    "print(len(X_test[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the labels in McFly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapclasses = {'DEL_start': 1, 'DEL_end': 0,  'noSV': 2}\n",
    "print(mapclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array([mapclasses[c] for c in y_train], dtype='int')\n",
    "y_val = np.array([mapclasses[c] for c in y_val], dtype='int')\n",
    "y_test = np.array([mapclasses[c] for c in y_test], dtype='int')\n",
    "y_train_binary = to_categorical(y_train)\n",
    "y_val_binary = to_categorical(y_val)\n",
    "y_test_binary = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_val_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Generate and train neural networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from mcfly import modelgen, find_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed = 321\n",
    "num_classes = y_train_binary.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "models = modelgen.generate_models(X_train.shape,\n",
    "                                  num_classes,\n",
    "                                  number_of_models = 1,\n",
    "                                  model_type = 'CNN',\n",
    "                                  cnn_min_layers=1,\n",
    "                                  cnn_max_layers=1,\n",
    "                                  cnn_min_filters = 3, \n",
    "                                  cnn_max_filters = 3, \n",
    "                                  cnn_min_fc_nodes=2, \n",
    "                                  cnn_max_fc_nodes=2,\n",
    "                                  low_lr=1.73, high_lr=1.73,\n",
    "                                  kernel_size = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "models = modelgen.generate_models(X_train.shape,\n",
    "                                  num_classes,\n",
    "                                  number_of_models = 1,\n",
    "                                  model_type = 'CNN',\n",
    "                                  cnn_min_layers=2,\n",
    "                                  cnn_max_layers=2,\n",
    "                                  cnn_min_filters =7, \n",
    "                                  cnn_max_filters = 18, \n",
    "                                  cnn_min_fc_nodes=8, \n",
    "                                  cnn_max_fc_nodes=8,\n",
    "                                  low_lr=1.97781612, high_lr=1.97781612,\n",
    "                                  kernel_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "i=0\n",
    "for model, params, model_types in models:\n",
    "    print('model ' + str(i))\n",
    "    i=i+1\n",
    "    print(params)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set_size = X_train.shape[0]\n",
    "train_set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "histories, val_accuracies, val_losses = find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                                 X_val, y_val_binary,\n",
    "                                                                                 models,nr_epochs=1, \n",
    "                                                                                 subset_size=train_set_size,\n",
    "                                                                                 verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 CNN {'regularization_rate': 0.0003805626772693005, 'filters': array([ 7, 14]), 'learning_rate': 0.010524071771634814, 'kernel_size': 5, 'fc_hidden_nodes': 8}\n"
     ]
    }
   ],
   "source": [
    "best_model_index = np.argmax(val_accuracies)\n",
    "best_model, best_params, best_model_types = models[best_model_index]\n",
    "print(best_model_index, best_model_types, best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = os.path.join('F:/CNN/notebooks/', 'Gtcg_01_11_32xoversample_NoDiff_')\n",
    "\n",
    "best_model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best model on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 173533 samples, validate on 43456 samples\n",
      "Epoch 1/1\n",
      "173533/173533 [==============================] - 167s 961us/step - loss: 0.0911 - acc: 0.9835 - val_loss: 4.5071 - val_acc: 0.3868\n"
     ]
    }
   ],
   "source": [
    "#We make a copy of the model, to start training from fresh\n",
    "nr_epochs = 1\n",
    "datasize = train_set_size # Change in `X_train.shape[0]` if training complete data set\n",
    "history = best_model.fit(X_train[:datasize,:,:], y_train_binary[:datasize,:],\n",
    "              epochs=nr_epochs, validation_data=(X_val, y_val_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "#model_path = os.path.join('F:/CNN/notebooks/',  'Gtcg_26_10_16xoversample_NoDiff_9682')\n",
    "model_path = os.path.join('F:/CNN/notebooks/',  'Gtcg_01_11_32xoversample_NoDiff_9715')\n",
    "model_reloaded = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect model predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = model_reloaded \n",
    "datasize = X_test.shape[0]\n",
    "probs = model.predict_proba(X_test[:datasize,:,:],batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns are predicted labels by DeepSV, rows are nanopore labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DEL_end', 0), ('DEL_start', 1), ('noSV', 2)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapclasses = {'DEL_end': 0, 'DEL_start': 1, 'noSV': 2}\n",
    "dict=mapclasses\n",
    "dict_sorted = sorted(dict.items(), key=lambda x: x[1])\n",
    "dict_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = [i[0] for i in dict_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEL_end</th>\n",
       "      <th>DEL_start</th>\n",
       "      <th>noSV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DEL_end</th>\n",
       "      <td>9295</td>\n",
       "      <td>130</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEL_start</th>\n",
       "      <td>325</td>\n",
       "      <td>10530</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noSV</th>\n",
       "      <td>107</td>\n",
       "      <td>134</td>\n",
       "      <td>10095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DEL_end  DEL_start   noSV\n",
       "DEL_end       9295        130    390\n",
       "DEL_start      325      10530    325\n",
       "noSV           107        134  10095"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "predicted = probs.argmax(axis=1)\n",
    "y_index = y_test_binary.argmax(axis=1)\n",
    "confusion_matrix = pd.crosstab(pd.Series(y_index), pd.Series(predicted))\n",
    "confusion_matrix.index = [labels[i] for i in confusion_matrix.index]\n",
    "confusion_matrix.columns = [labels[i] for i in confusion_matrix.columns]\n",
    "confusion_matrix.reindex(columns=[l for l in labels], fill_value=0)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best current model on testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss and accuracy of best model: [0.29208025244105323, 0.95496473141616933]\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_test = model.evaluate(X_test, y_test_binary, verbose=False)\n",
    "print('Test loss and accuracy of best model: ' + str(score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
