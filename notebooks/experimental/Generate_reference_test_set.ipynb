{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save a channel and label data for the NA12878 sample with the Mills2011_nanosv labels, for Chr[1,2,3]\n",
    "## This dataset is used as a reference test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "import gzip\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "\n",
    "def transposeDataset(X):\n",
    "    image = []\n",
    "    for i in range (0, len(X -1)):\n",
    "        tr = X[i].transpose()\n",
    "        image.append(tr)\n",
    "    return np.array(image)\n",
    "\n",
    "def write_prec_rec(y_binary, probs):\n",
    "    \n",
    "    df_conf = pd.DataFrame()\n",
    "\n",
    "    for i in np.linspace(1.0 / len(labels), 1, num=50, endpoint=False):\n",
    "\n",
    "        predicted = np.argwhere(probs > i)[:, 1]\n",
    "        y_index = np.argwhere(y_binary > i)[:, 1]\n",
    "\n",
    "        # Rows: true, columns: predicted\n",
    "        confusion_matrix = pd.crosstab(pd.Series(y_index), pd.Series(predicted))\n",
    "        confusion_matrix.index = [labels[i] for i in confusion_matrix.index]\n",
    "        confusion_matrix.columns = [labels[i] for i in confusion_matrix.columns]\n",
    "        confusion_matrix.reindex(columns=[l for l in labels], fill_value=0)\n",
    "\n",
    "        for l in labels:\n",
    "            if l in confusion_matrix.index:\n",
    "                \n",
    "                label_precision = np.around(confusion_matrix.loc[l, l] / sum(confusion_matrix.loc[:, l]) * 100)\n",
    "                label_recall = np.around(confusion_matrix.loc[l, l] / sum(confusion_matrix.loc[l, :]) * 100)\n",
    "                label_F1 = 2 * (label_precision * label_recall) / (label_precision + label_recall)\n",
    "\n",
    "                # print(f'Iter:{i} {l} -> Precision:{label_precision}%, Recall:{label_recall}%, F1:{label_F1}')\n",
    "\n",
    "                df_intres = pd.DataFrame(\n",
    "                    {'iteration': [i], 'label': [l],\n",
    "                     'precision': [label_precision], 'recall': [label_recall], 'F1': [label_F1]})\n",
    "                df_conf = df_conf.append(df_intres)\n",
    "\n",
    "    # print(df_conf)\n",
    "    df_conf.to_csv(path_or_buf=os.path.join(datapath_now,'model_PrecRec.csv'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name = 'NA12878'\n",
    "#date = '231118'\n",
    "date = '270219'\n",
    "label_type = 'Mills2011_nanosv'\n",
    "\n",
    "# Load label dictionary\n",
    "dico_file = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData_'+date+'/'+sample_name+'/MultiLabelData/labels.pickle.gz'\n",
    "with gzip.GzipFile(dico_file, \"rb\") as f:\n",
    "    dico = np.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3']\n",
      "Loading data for Chr1\n",
      "Loading data for Chr2\n",
      "Loading data for Chr3\n",
      "Counter({'noSV': 258257, 'UK': 328, 'DEL_start': 302, 'DEL_end': 254})\n"
     ]
    }
   ],
   "source": [
    "# Create reference test set using Chr1 to Chr3\n",
    "\n",
    "#Leaving out chromosome Y and MT for the moment\n",
    "chr_list = list(map(str, np.arange(1,4)))\n",
    "\n",
    "print(chr_list)\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "test_id = []\n",
    "\n",
    "datapath = '/hpc/cog_bioinf/ridder/users/lsantuari/Processed/Test/'+date+'/TestData_'+date+'/'+sample_name+'/ChannelData/'\n",
    "\n",
    "for i in chr_list:\n",
    "    \n",
    "    print('Loading data for Chr%s' % i)\n",
    "    data_file = datapath + sample_name + '_' + str(i) + '.npy.gz'\n",
    "    with gzip.GzipFile(data_file, \"rb\") as f:\n",
    "        data_mat = np.load(f)\n",
    "        test_data.extend(data_mat)\n",
    "    f.close()\n",
    "    \n",
    "    test_labels.extend(dico[label_type][i])\n",
    "    test_id.extend([d['chromosome']+'_'+str(d['position']) for d in dico['id'][i]])\n",
    "    \n",
    "print(Counter(test_labels))\n",
    "assert len(test_data) == len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "test_id = np.array(test_id)\n",
    "\n",
    "# Remove windows labelled as unknown ('UK')\n",
    "keep = np.where(np.array(test_labels)!='UK')\n",
    "test_data = test_data[keep]\n",
    "test_labels = test_labels[keep]\n",
    "test_id = test_id[keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'noSV': 258257, 'DEL_start': 302, 'DEL_end': 254})\n",
      "Minimum number of labels = 254\n",
      "Counter({'noSV': 254, 'DEL_start': 254, 'DEL_end': 254})\n"
     ]
    }
   ],
   "source": [
    "cnt_lab = Counter(test_labels)\n",
    "min_v = min([v for k, v in cnt_lab.items()])\n",
    "print(cnt_lab)\n",
    "print('Minimum number of labels = ' + str(min_v))\n",
    "\n",
    "data_balanced = []\n",
    "labels_balanced = []\n",
    "id_balanced = []\n",
    "\n",
    "for l in cnt_lab.keys():\n",
    "    #print(l)\n",
    "    iw = np.where(test_labels==l)\n",
    "    ii = iw[0][:min_v]\n",
    "    data_balanced.extend(test_data[ii])\n",
    "    labels_balanced.extend(test_labels[ii])\n",
    "    id_balanced.extend(test_id[ii])\n",
    "\n",
    "print(Counter(labels_balanced))\n",
    "\n",
    "X = np.array(data_balanced)\n",
    "y = np.array(labels_balanced)\n",
    "z = np.array(id_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Remove windows with nan if present\n",
    "print(X[np.where(np.isnan(X))])\n",
    "idx = numpy.unique(np.where(np.isnan(X))[0])\n",
    "X = np.delete(X, idx, 0)\n",
    "y = np.delete(y, idx, 0)\n",
    "z = np.delete(z, idx, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transposeDataset(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapclasses = {'DEL_start': 1, 'DEL_end': 0,  'noSV': 2}\n",
    "y_num = np.array([mapclasses[c] for c in y], dtype='int')\n",
    "y_binary = to_categorical(y_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(762, 200, 29)\n",
      "(762,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save channels and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 s, sys: 336 ms, total: 2.08 s\n",
      "Wall time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import errno\n",
    "\n",
    "datapath_test=os.path.join(datapath,'../TestData/')\n",
    "\n",
    "try:\n",
    "    os.mkdir(datapath_test)\n",
    "except OSError as exc:\n",
    "    if exc.errno != errno.EEXIST:\n",
    "        raise\n",
    "    pass\n",
    "\n",
    "data_output_file = datapath_test + sample_name + '_' + label_type + '_channels.npy'\n",
    "np.save(data_output_file, X)\n",
    "os.system('gzip '+data_output_file)\n",
    "\n",
    "label_output_file = datapath_test + sample_name + '_' + label_type + '_labels.npy'\n",
    "np.save(label_output_file, y)\n",
    "os.system('gzip '+label_output_file)\n",
    "\n",
    "label_output_file = datapath_test + sample_name + '_' + label_type + '_labels_binary.npy'\n",
    "np.save(label_output_file, y_binary)\n",
    "os.system('gzip '+label_output_file)\n",
    "\n",
    "id_output_file = datapath_test + sample_name + '_' + label_type + '_ids.npy'\n",
    "np.save(id_output_file, z)\n",
    "os.system('gzip '+id_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
