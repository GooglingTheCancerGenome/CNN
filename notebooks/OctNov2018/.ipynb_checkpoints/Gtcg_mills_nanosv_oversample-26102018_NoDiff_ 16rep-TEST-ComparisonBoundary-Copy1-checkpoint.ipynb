{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests on parts of  NA12878 data for Del_st, Del_end and No_sv, ground  truth Mills_nanosv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a network trained on a random subsample of NoSv, and apply it to the whole training set. Then we are going to take the confused NoSvs as training Nosvs to a nother network\n",
    "The training set is the first 16 chromozomzes, the test is the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependences and setting output configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dico = pickle.load(open(\"/home/ubuntu/GTCG_labels/labels.pickle\", \"rb\"))\n",
    "data_labels = dataset = dico[\"Mills2011_nanosv\"]\n",
    "window_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dico = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replications = 16\n",
    "factor_nosv = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# after iteration 4 I was taking only the SV windows because of memory problems and because I don't really need all nosv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noSV\n",
      "1:(222, 27, 200)\n",
      "noSV\n",
      "2:(205, 27, 200)\n",
      "noSV\n",
      "3:(208, 27, 200)\n",
      "noSV\n",
      "4:(228, 27, 200)\n",
      "noSV\n",
      "5:(214, 27, 200)\n",
      "noSV\n",
      "6:(162, 27, 200)\n",
      "noSV\n",
      "7:(163, 27, 200)\n",
      "noSV\n",
      "8:(135, 27, 200)\n",
      "noSV\n",
      "9:(127, 27, 200)\n",
      "noSV\n",
      "10:(107, 27, 200)\n",
      "noSV\n",
      "11:(119, 27, 200)\n",
      "noSV\n",
      "12:(114, 27, 200)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e8d4d5af533a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mG1_data_SV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG1_data_SV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG1_data_SV_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mG1_labels_SV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG1_labels_SV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG1_labels_SV_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mG1_data_noSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG1_data_noSV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG1_data_noSV_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mG1_labels_noSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG1_labels_noSV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG1_labels_noSV_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#for training until chromozome 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datapath = '/home/ubuntu/GTCG_data' \n",
    "\n",
    "\n",
    "germline_1_datapath = datapath + '/'\n",
    "#ger_1_labels_datapath = datapath + '/LabelData/unzipped/'\n",
    "\n",
    "G1_data_SV = np.empty([0, 27, window_size])\n",
    "G1_labels_SV =[]\n",
    "G1_data_noSV = np.empty([0, 27, window_size])\n",
    "G1_labels_noSV =[]\n",
    "total_train_sv_windows = 0\n",
    "for i in range(1,16,1):\n",
    "        G1_data_new =np.load(germline_1_datapath + str(i)  +'_channel_maker_real_germline.npy')\n",
    "        #G1_labels_new = np.load(ger_1_labels_datapath  +  str(i) +'_label_ci_full_overlap.npy/' +str(i) +'_label_ci_full_overlap.npy') \n",
    "        G1_labels_new = np.array(data_labels[str(i)])\n",
    "        print(G1_labels_new[0])\n",
    "        G1_data_new = G1_data_new[np.where(G1_labels_new != 'UK')]\n",
    "        G1_labels_new = G1_labels_new[np.where(G1_labels_new != 'UK')]\n",
    "        G1_data_SV_new  = G1_data_new[np.where(G1_labels_new != 'noSV')]\n",
    "        G1_labels_SV_new  = G1_labels_new[np.where(G1_labels_new != 'noSV')]\n",
    "        n_windows_sv = G1_data_SV_new.shape[0]\n",
    "        G1_data_noSV_new  = G1_data_new[np.where(G1_labels_new == 'noSV')]\n",
    "        G1_labels_noSV_new  = G1_labels_new[np.where(G1_labels_new == 'noSV')]\n",
    "        #G1_data_noSV_new =  G1_data_noSV_new[0:int(replications*n_windows_sv/2/factor_nosv)]\n",
    "        #G1_labels_noSV_new =  G1_labels_noSV_new[0:int(replications*n_windows_sv/2/factor_nosv)]\n",
    "        print(str(i) + ':' + str(G1_data_SV_new.shape))\n",
    "        #print(G1_labels_SV_new[0])\n",
    "        G1_data_SV = np.concatenate((G1_data_SV, G1_data_SV_new))\n",
    "        G1_labels_SV = np.concatenate((G1_labels_SV, G1_labels_SV_new))\n",
    "        G1_data_noSV = np.concatenate((G1_data_noSV, G1_data_noSV_new))\n",
    "        G1_labels_noSV = np.concatenate((G1_labels_noSV, G1_labels_noSV_new))\n",
    "        if i < 16: #for training until chromozome 16\n",
    "            total_train_sv_windows += G1_data_SV_new.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find  the indexes that split the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_splitting_indices(labels):\n",
    "    for i in range (0, labels.shape[0] - 1):\n",
    "        if (labels[i] != labels[i+1]):\n",
    "            print(i , ': ', labels[i] , labels[i+1] )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find_splitting_indices(G1_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G1_labels_SV = ['DEL'] * G1_labels_SV.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sv=G1_data_SV.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(sv/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G1_data_noSV  = G1_data_noSV[0:2*sv] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G1_labels_noSV  = G1_labels_noSV[0:2*sv] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SV_train =  0 #int(0.8 * total_train_sv_windows)\n",
    "noSV_train = 0 #int(replications * SV_train / 2/factor_nosv)\n",
    "\n",
    "SV_val = 0 # total_train_sv_windows - SV_train\n",
    "noSV_val = 0 # int(replications * SV_val / 2/factor_nosv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replicate(data, start, end, howmanytimes): \n",
    "    X = data[start:end]\n",
    "    for i in range(0,howmanytimes):\n",
    "        X = np.concatenate((X, data[start:end]))\n",
    "    return X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replications = 1#no rep for testing\n",
    "X_train = replicate(G1_data_SV, 0, SV_train, replications)\n",
    "y_train = replicate(G1_labels_SV, 0, SV_train,replications)\n",
    "X_val = replicate(G1_data_SV, SV_train, SV_train+SV_val, replications)\n",
    "y_val = replicate(G1_labels_SV, SV_train, SV_train+SV_val, replications)\n",
    "X_test = replicate(G1_data_SV, SV_train+SV_val, len(G1_data_SV), replications)\n",
    "y_test = replicate(G1_labels_SV, SV_train+SV_val, len(G1_labels_SV), replications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_data_noSV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1_data_noSV = G1_data_noSV[0:200000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1_labels_noSV = G1_labels_noSV[0:200000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, G1_data_noSV[0:noSV_train ]))\n",
    "X_val = np.concatenate((X_val, G1_data_noSV[noSV_train:noSV_train +noSV_val ]))\n",
    "X_test = np.concatenate((X_test, G1_data_noSV[noSV_train +noSV_val:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1_data_noSV = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_train, G1_labels_noSV[0:noSV_train ]))\n",
    "y_val = np.concatenate((y_val, G1_labels_noSV[noSV_train:noSV_train +noSV_val ]))\n",
    "y_test = np.concatenate((y_test, G1_labels_noSV[noSV_train +noSV_val:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#G1_labels_noSV = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of training, validation and test windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_channels = X_train.shape[1]\n",
    "number_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data using the reads coverage as parameter and remove uninteresting channels for deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = np.median(X_test[:, 0, :]) #the median of the coverage in the normal cells\n",
    "coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X):       \n",
    "    for i in range (0, len(X)):                              \n",
    "        for j in range(0,number_channels):                                                                                            \n",
    "            X[i][j] = np.divide(X[i][j], coverage)*100 \n",
    "normalize(X_train)\n",
    "normalize(X_val)\n",
    "normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eliminate_noise_chanels(X):\n",
    "    return np.delete(X, [4-1,5-1,6-1,7-1,8-1,9-1,10-1,12-1,13-1,15-1,16-1, 17-1,18-1,19-1,23-1,24-1,26-1,27-1], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eliminate_distance_chanels(X):\n",
    "    return np.delete(X, [3,4,7,8], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = eliminate_noise_chanels(X_train)\n",
    "X_val = eliminate_noise_chanels(X_val)\n",
    "X_test = eliminate_noise_chanels(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = eliminate_distance_chanels(X_train)\n",
    "X_val = eliminate_distance_chanels(X_val)\n",
    "X_test = eliminate_distance_chanels(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_channels = X_train.shape[1]\n",
    "number_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiate the time series for a zero mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def differentiate(X):\n",
    "    for i in range(0, X.shape[0]):        \n",
    "        for j in range(0, X.shape[1]):\n",
    "            for k in range(0, X.shape[2]-1):\n",
    "                X[i][j][k] = X[i][j][k+1] - X[i][j][k]\n",
    "    return X[:,:,:-1]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train = differentiate(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_val = differentiate(X_val)\n",
    "#X_test = differentiate(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots several  windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_windows = 100\n",
    "label = [\"None\"] * number_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label[0] = \"germline:coverage\"\n",
    "label[1] = \"germline:#left clipped reads\"\n",
    "label[2] = \"germline:#right clipped reads\"\n",
    "label[3] = \"germline:#split reads right split\"\n",
    "label[4] = \"germline:#split reads left split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors =['b','g', 'm', 'gray', 'r','c', 'darkgreen' ,'y', 'k', 'orange', 'gray']\n",
    "\n",
    "def plot_channels(start_window, n_windows):\n",
    "    for i in range (start_window, start_window + n_windows, 1):\n",
    "        if labels[y_test[i]] == labels[predicted[i]]:\n",
    "            continue\n",
    "        #print(y_train[i], 'id:', i)\n",
    "        print('id:', i)\n",
    "        print('Nanopore:', labels[y_test[i]], '. DeepSV:', labels[predicted[i]])\n",
    "        for j in range (0, number_channels):   \n",
    "            shift = 0\n",
    "            start =0\n",
    "            if j in [0,11]:\n",
    "                shift = -100\n",
    "            if j > 8:\n",
    "                start = -60\n",
    "            Z = [start + shift + 300 + x - 5*j*4 for x in X_test[i][j]]  \n",
    "            plt.ylim([150,450])\n",
    "            if np.max(Z) > 1000:\n",
    "                plt.ylim([-200,1000])\n",
    "                Z = [start + shift + 300 + x - 5*j*4 - 400 for x in X_test[i][j]]  \n",
    "            if j>8:\n",
    "                plt.plot(Z,  label = label[j], linestyle=':', linewidth=1.5, color = colors[j % 9])\n",
    "            else:\n",
    "                plt.plot(Z,  label = label[j], color = colors[j])\n",
    "        \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., prop={'size': 10})    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_window = 0\n",
    "n_windows = 5000\n",
    "plot_channels(start_window, n_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_windows = 1000\n",
    "start_window = 10500\n",
    "plot_channels(start_window, n_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "## Transposes every window in X, to comply to McFly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transposeDataset(X):\n",
    "    image = []\n",
    "    for i in range (0, len(X -1)):\n",
    "        tr = X[i].transpose()\n",
    "        image.append(tr)\n",
    "    return np.array(image)\n",
    "\n",
    "image1 = transposeDataset(X_train)\n",
    "image2 = transposeDataset(X_val)\n",
    "image3 = transposeDataset(X_test)\n",
    "X_train = image1\n",
    "X_val = image2\n",
    "X_test = image3\n",
    "\n",
    "n_channels = len(X_test[0][0])\n",
    "print(len(X_test[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the labels in McFly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapclasses = {'DEL_start': 1, 'DEL_end': 0,  'noSV': 2}\n",
    "print(mapclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#y_train = np.array([mapclasses[c] for c in y_train], dtype='int')\n",
    "#y_val = np.array([mapclasses[c] for c in y_val], dtype='int')\n",
    "y_test = np.array([mapclasses[c] for c in y_test], dtype='int')\n",
    "#y_train_binary = to_categorical(y_train)\n",
    "#y_val_binary = to_categorical(y_val)\n",
    "y_test_binary = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "model_path = os.path.join('/home/ubuntu/CNN/notebooks/',  'Gtcg_01_11_32xoversample_NoDiff_9715')\n",
    "model_reloaded = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect model predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = model_reloaded \n",
    "datasize = X_test.shape[0]\n",
    "probs = model.predict_proba(X_test[:datasize,:,:],batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns are predicted labels by DeepSV, rows are nanopore labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapclasses = {'DEL_end': 0, 'DEL_start': 1, 'noSV': 2}\n",
    "dict=mapclasses\n",
    "dict_sorted = sorted(dict.items(), key=lambda x: x[1])\n",
    "dict_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [i[0] for i in dict_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predicted = probs.argmax(axis=1)\n",
    "y_index = y_test_binary.argmax(axis=1)\n",
    "confusion_matrix = pd.crosstab(pd.Series(y_index), pd.Series(predicted))\n",
    "confusion_matrix.index = [labels[i] for i in confusion_matrix.index]\n",
    "confusion_matrix.columns = [labels[i] for i in confusion_matrix.columns]\n",
    "confusion_matrix.reindex(columns=[l for l in labels], fill_value=0)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best current model on testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "score_test = model.evaluate(X_test, y_test_binary, verbose=False)\n",
    "print('Test loss and accuracy of best model: ' + str(score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#9659 best test results : 9513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4000/25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " print('Nanopore:', labels[y_test[i]], '. DeepSV:', labels[predicted[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1_data_noSV_confused = X_test[np.where(y_test == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1_labels_noSV_confused = y_test[np.where(y_test == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_confused = predicted[np.where(y_test == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1_data_noSV_confused = G1_data_noSV_confused[np.where(predicted_confused != 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G1_labels_noSV_confused = G1_labels_noSV_confused[np.where(predicted_confused != 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_confused = predicted_confused[np.where(predicted_confused != 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_data_noSV_confused.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_labels_noSV_confused.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_confused.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(germline_1_datapath + \"G1_data_noSV_confused.npy\", G1_data_noSV_confused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(ger_1_labels_datapath + \"G1_labels_noSV_confused.npy\", G1_labels_noSV_confused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
